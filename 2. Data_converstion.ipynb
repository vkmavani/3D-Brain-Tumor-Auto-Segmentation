{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data-converstion.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "dDiRAQ_g_AsX",
        "dhwMvNjN_ar3",
        "dedJs295_FQk",
        "guC17GBNcJPz"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuZE28DkwatQ"
      },
      "source": [
        "## **.nii to Tensor data coverstion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDiRAQ_g_AsX"
      },
      "source": [
        "### *Import Libraries*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqP2NaGN_E6L"
      },
      "source": [
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meBOab7e_EvE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhwMvNjN_ar3"
      },
      "source": [
        "### *Load file and Extract the data as a numpy array*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqU5kd1z_aIX"
      },
      "source": [
        "DATA_DIR = '/content/drive/My Drive/BrainTumourData/'\n",
        "\n",
        "# This will return numpy array\n",
        "def load_case(image_nifty_file, label_nifty_file):\n",
        "    image = np.array(nib.load(image_nifty_file).get_fdata())\n",
        "    label = np.array(nib.load(label_nifty_file).get_fdata())\n",
        "    return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEqle-z-CYYU"
      },
      "source": [
        "# Only for visualization\n",
        "\n",
        "#image,label = load_case(DATA_DIR + \"imagesTr/BRATS_001.nii.gz\", DATA_DIR + \"labelsTr/BRATS_001.nii.gz\")\n",
        "#image = utils.get_labeled_image(image,label)\n",
        "#plt.imshow(image[:, :, 54])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A35i_NrlEiOL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dedJs295_FQk"
      },
      "source": [
        "### *Data Pre-processing*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSMLd5xb-G5s"
      },
      "source": [
        "# Sub-volume Sampling\n",
        "\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "def get_sub_volume(image, label, \n",
        "                   orig_x = 240, orig_y = 240, orig_z = 155, \n",
        "                   output_x = 160, output_y = 160, output_z = 16,\n",
        "                   num_classes = 4, max_tries = 1000, background_threshold = 0.95):\n",
        "    X = None\n",
        "    y = None\n",
        "    tries = 0\n",
        "\n",
        "    while tries < max_tries:\n",
        "        # randomly sample sub-volume by sampling the corner voxel\n",
        "        start_x = np.random.randint(orig_x - output_x + 1)\n",
        "        start_y = np.random.randint(orig_y - output_y + 1)\n",
        "        start_z = np.random.randint(orig_z - output_z + 1)\n",
        "\n",
        "        # extract relevant area of label\n",
        "        y = label[start_x: start_x + output_x,\n",
        "                  start_y: start_y + output_y,\n",
        "                  start_z: start_z + output_z]\n",
        "\n",
        "        y = to_categorical(y, num_classes)          # (output_x, output_y, output_z, num_classes)\n",
        "\n",
        "        bgrd_ratio = y[:, :, :, 0].sum() / (output_x * output_y * output_z)             # compute the background ratio\n",
        "\n",
        "        tries += 1\n",
        "\n",
        "        if (bgrd_ratio < background_threshold):\n",
        "\n",
        "            X = np.copy(image[start_x: start_x + output_x,\n",
        "                              start_y: start_y + output_y,\n",
        "                              start_z: start_z + output_z, :])\n",
        "            X = np.moveaxis(X, -1, 0)       # (num_channels, x_dim, y_dim, z_dim)\n",
        "            y = np.moveaxis(y, -1, 0)       # (num_classes, x_dim, y_dim, z_dim)\n",
        "            y = y[1:, :, :, :]              # take a subset of y that excludes the background class\n",
        "    \n",
        "            return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fv10lat9_1XH"
      },
      "source": [
        "# Standardization\n",
        "\n",
        "def standardize(image):\n",
        "\n",
        "    standardized_image = np.zeros(image.shape)\n",
        "    # iterate over channels\n",
        "    for c in range(image.shape[0]):\n",
        "        for z in range(image.shape[3]):\n",
        "\n",
        "            image_slice = image[c,:,:,z]                 # get a slice of the image at channel 'c' and z-th dimension 'z'\n",
        "            centered = image_slice - image_slice.mean()\n",
        "            if np.std(centered) != 0:\n",
        "                centered_scaled = image_slice / image_slice.std()\n",
        "                standardized_image[c, :, :, z] = centered_scaled\n",
        "\n",
        "    return standardized_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGn1emQUBARK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guC17GBNcJPz"
      },
      "source": [
        "### *Data Conversion*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOzoxhLpcH-K"
      },
      "source": [
        "def create_dataset(data_dir, patches=100):\n",
        "\n",
        "    idx = random.sample(list(range(1,484)), patches)\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for i in idx:\n",
        "\n",
        "        if i<10:\n",
        "            i = 'BRATS_00' + str(i) + '.nii.gz'\n",
        "        elif i>=10 and i<100:\n",
        "            i = 'BRATS_0' + str(i) + '.nii.gz'\n",
        "        elif i>=100:\n",
        "            i = 'BRATS_' + str(i) + '.nii.gz'\n",
        "\n",
        "        image, label = load_case(data_dir + 'imagesTr/' + i,\n",
        "                                 data_dir + 'labelsTr/' + i)\n",
        "\n",
        "        try: \n",
        "            X,y = get_sub_volume(image, label)\n",
        "            X = standardize(X)\n",
        "            images.append(X)\n",
        "            labels.append(y)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    return images, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3UFf-FBdnF2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxVOfGxNJJ65"
      },
      "source": [
        "### *Save converted data*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFui3ZWDdnDf"
      },
      "source": [
        "images,labels = create_dataset(DATA_DIR, patches=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zne9DLt9RSMA",
        "outputId": "adfa6c95-dd30-44bc-c754-a60bab8f778f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Length of data : ', len(images))\n",
        "print('Shape of each image : ', images[0].shape)\n",
        "print('Shape of each label : ', labels[0].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of data :  173\n",
            "Shape of each image :  (4, 160, 160, 16)\n",
            "Shape of each label :  (3, 160, 160, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DQGizq0KBWV"
      },
      "source": [
        "# change datatype as 'FloatTensor'\n",
        "\n",
        "images = torch.FloatTensor(images)\n",
        "labels = torch.FloatTensor(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYPXPaRBYnOh",
        "outputId": "e9ff3d11-7646-44bb-c0d3-bce9b124f0a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Length of data : ', len(images))\n",
        "print('Shape of each image : ', images[0].shape)\n",
        "print('Shape of each label : ', labels[0].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of data :  173\n",
            "Shape of each image :  torch.Size([4, 160, 160, 16])\n",
            "Shape of each label :  torch.Size([3, 160, 160, 16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvEQGVpaKDRS"
      },
      "source": [
        "torch.save(images,'/content/drive/My Drive/BrainTumourData/TensorData/X.pt')\n",
        "torch.save(labels,'/content/drive/My Drive/BrainTumourData/TensorData/y.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-Z5lHOVOJlb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}